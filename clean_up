#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Feb 25 14:51:15 2023

@author: NatStrom
"""
## my data is a panel
## (robust) clustered standard errors
## fixed effects or random effects
##data clean up DALY WASH
import pandas as pd
import numpy as np
import os

##set a working directory
user = os.path.expanduser('~')
user

os.makedirs(f'{user}/Desktop/', exist_ok=True) 

path = os.chdir(f'{user}/Desktop/'+'thesis/risk SSA/')
file_list = os.listdir(path)
file_list

# =============================================================================
## 1. IMPORT THE DATA
# =============================================================================
#import the csv files into one dataframe
file= pd.concat(map(pd.read_csv,['IHME-GBD_2019_DATA-ff404857-1.csv',
 'IHME-GBD_2019_DATA-ff404857-2.csv',
 'IHME-GBD_2019_DATA-ff404857-3.csv',
 'IHME-GBD_2019_DATA-ff404857-7.csv',
 'IHME-GBD_2019_DATA-ff404857-6.csv',
 'IHME-GBD_2019_DATA-ff404857-4.csv',
 'IHME-GBD_2019_DATA-ff404857-5.csv',
 'IHME-GBD_2019_DATA-ff404857-11.csv',
 'IHME-GBD_2019_DATA-ff404857-10.csv',
 'IHME-GBD_2019_DATA-ff404857-12.csv',
 'IHME-GBD_2019_DATA-ff404857-13.csv',
 'IHME-GBD_2019_DATA-ff404857-17.csv',
 'IHME-GBD_2019_DATA-ff404857-16.csv',
 'IHME-GBD_2019_DATA-ff404857-14.csv',
 'IHME-GBD_2019_DATA-ff404857-15.csv',
 'IHME-GBD_2019_DATA-ff404857-18.csv',
 'IHME-GBD_2019_DATA-ff404857-8.csv',
 'IHME-GBD_2019_DATA-ff404857-9.csv']))
df = file.copy()
df.head()

# =============================================================================
## 2. GET DESCRIPTIVES OF DATASET
# =============================================================================
print(df.dtypes)
print(df.columns)
print(df.describe(include='all'))

## sanity check to ensure the spread of the data is correct
print('sanity check 1, ensure appropriate years and countries are represented')
list_country=list(list(df['location_name'].drop_duplicates()))
print('country list', list_country)
#inspect for NAs
print('following checks for completeness of all columns')
print('is country_id null', df['location_id'].isnull().values.any())
print('is risk_id null', df['rei_id'].isnull().values.any())
print('is risk_name null', df['rei_name'].isnull().values.any())
print('is year null', df['year'].isnull().values.any())
print('is sex null', df['sex_id'].isnull().values.any())
print('is age_group null', df['age_id'].isnull().values.any())
print('is daly_mean null', df['val'].isnull().values.any())
print('these age groups have been pulled', df['age_name'].unique())
print('these sex groups have been pulled', df['sex_name'].unique())
print('these years have been pulled', df['year'].unique())
print('these risks have been pulled', df['rei_name'].unique())

# =============================================================================
# ## 3. FILTER, RENAME AND CLEAN
# =============================================================================
#filter only the wanted columns
df = df.loc[df['metric_id'].isin([3])]
df_filtered = df.filter(['measure_name', 'location_name',
                         'sex_name', 'age_name', 'rei_id', 'cause_name',
                         'cause_id','rei_name', 'year', 'val', 'upper',
                         'lower'])
#change dtypes if neccessary
df_filtered['val'] = df_filtered['val'].astype(int)
df_filtered['upper'] = df_filtered['upper'].astype(int)
df_filtered['lower'] = df_filtered['lower'].astype(int)

#rename columns
df_filtered = df_filtered.rename(columns={'location_name': 'country',
                                          'sex_name': 'sex',
                                          'age_name':'age',
                                          'val': 'daly_mean',
                                          'upper': 'daly_upper',
                                          'lower': 'daly_lower'})
#create country group/ region id
def categorize(row):  
    if row['country'] ==  'Comoros' or row['country']=='Djibouti' or row['country']=='Ethiopia' or row['country'] == 'Uganda' or row['country']== 'United Republic of Tanzania' or row['country']== 'Kenya' or row['country']== 'Burundi' or row['country']=='Eritrea' or row['country']== 'South Sudan' or row['country']== ' Rwanda' or row['country']=='Somalia' or row['country']==  'Mozambique' or row['country']== 'Zambia' or row['country']== 'Zimbabwe' or row['country']=='Madagascar':
        return 'SSA_east'
    if row ['country'] == 'Mauretania' or row['country']== 'Equatorial Guinea' or row['country']=='Gambia' or row['country']=='Cabo Verde' or row['country']=='Benin' or row['country']=='Niger' or row['country'] == 'Côte d´Ivoire' or row['country']== 'Nigeria' or row['country']== 'Burkina Faso' or row['country']=='Liberia' or row['country']=='Mali' or row['country']=='Sierra Leone' or row['country']=='Senegal' or row['country']=='Guinea-Bissau' or row['country']=='Ghana' or row['country']=='Cameroon':
        return 'SSA_west'
    if  row['country']=='Namibia' or row['country']=='Eswatini' or row['country']=='Botswana'  or row['country']=='Lesotho':
        return 'SSA_south'
    return 'SSA_middle'
df_filtered['region_SSA'] = df_filtered.apply(lambda row: categorize(row), axis=1)

#fix gender naming
#fix naming of the gender values
df_filtered = df_filtered.replace({'Both': 'btsx','Male':'mle','Female':'fmle'})

#fix coury names to match the right iso
df_filtered = df_filtered.replace({'Democratic Republic of the Congo': 'Congo, DRC','United Republic of Tanzania':'Tanzania'})

#only filter our level 3 WASH risk factors
df_WASH =df_filtered.copy()
print(df_WASH.rei_id.unique())
print(df_WASH.rei_name.unique())
df_WASH = df_WASH.loc[df_WASH['rei_id'].isin([238,83,84])]
print(df_WASH)

#get iso3 codes for countries
##mport the function 
import pycountry
def findCountryAlpha3 (country_name):
    """Producing current iso alpha 3 codes from standardized country names"""
    try:
        return pycountry.countries.get(name=country_name).alpha_3
    except:
        return ('')

##create iso codes
df_WASH['iso'] = df_WASH.apply(lambda row: findCountryAlpha3(row.country), axis=1)

##check the uniqueness and coverage of the iso codes
inspect = df_WASH[df_WASH['iso'].isna()]
inspect['iso'].unique()

list_iso = list(df_WASH.iso)
list_iso = list( dict.fromkeys(list_iso) )
print(list_iso)

##set iso manually for countries that were missed
#df.loc[df['country_column'] == "Cote d'Ivoire", 'iso'] = 'CIV'

#clear out the rows with '' in iso names
df_WASH = df_WASH.dropna(subset=['iso'])
list(df_WASH.country.unique())
df_WASH.head()
df_WASH.columns
#df_East = df_WASH.loc[df_WASH['region_SSA'].isin(['SSA_east'])]
# standardize the years
#df_East_standard = df_East.copy()
df_WASH_standard = df_WASH.copy()
df_WASH_standard = df_WASH_standard.loc[(df_WASH_standard['age']=='All ages') & (df_WASH_standard['sex']=='btsx')]
df_WASH_standard
#safe data to csv as back up
os.getcwd()
df_WASH_standard.to_csv('df_DALY_SSA.csv')
